import streamlit as st
import asyncio
import nest_asyncio
import json
import os
import platform

if platform.system() == "Windows":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# nest_asyncio ì ìš©: ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ë‚´ì—ì„œ ì¤‘ì²© í˜¸ì¶œ í—ˆìš©
nest_asyncio.apply()

# ì „ì—­ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„± ë° ì¬ì‚¬ìš© (í•œë²ˆ ìƒì„±í•œ í›„ ê³„ì† ì‚¬ìš©)
if "event_loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    st.session_state.event_loop = loop
    asyncio.set_event_loop(loop)

from langgraph.prebuilt import create_react_agent
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from utils import astream_graph, random_uuid
from langchain_core.messages.ai import AIMessageChunk
from langchain_core.messages.tool import ToolMessage
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì—ì„œ API í‚¤ ë“±ì˜ ì„¤ì •ì„ ê°€ì ¸ì˜´)
load_dotenv(override=True)

# config.json íŒŒì¼ ê²½ë¡œ ì„¤ì •
CONFIG_FILE_PATH = "config.json"

# JSON ì„¤ì • íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_config_from_json():
    """
    config.json íŒŒì¼ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

    ë°˜í™˜ê°’:
        dict: ë¡œë“œëœ ì„¤ì •
    """
    default_config = {
        "get_current_time": {
            "command": "python",
            "args": ["./mcp_server_time.py"],
            "transport": "stdio"
        }
    }
    
    try:
        if os.path.exists(CONFIG_FILE_PATH):
            with open(CONFIG_FILE_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ íŒŒì¼ ìƒì„±
            save_config_to_json(default_config)
            return default_config
    except Exception as e:
        st.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return default_config

# JSON ì„¤ì • íŒŒì¼ ì €ì¥ í•¨ìˆ˜
def save_config_to_json(config):
    """
    ì„¤ì •ì„ config.json íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        config (dict): ì €ì¥í•  ì„¤ì •
    
    ë°˜í™˜ê°’:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        with open(CONFIG_FILE_PATH, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        st.error(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

# ë¡œê·¸ì¸ ì„¸ì…˜ ë³€ìˆ˜ ì´ˆê¸°í™”
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

# ë¡œê·¸ì¸ í•„ìš” ì—¬ë¶€ í™•ì¸
use_login = os.environ.get("USE_LOGIN", "false").lower() == "true"

# ë¡œê·¸ì¸ ìƒíƒœì— ë”°ë¼ í˜ì´ì§€ ì„¤ì • ë³€ê²½
if use_login and not st.session_state.authenticated:
    # ë¡œê·¸ì¸ í˜ì´ì§€ëŠ” ê¸°ë³¸(narrow) ë ˆì´ì•„ì›ƒ ì‚¬ìš©
    st.set_page_config(page_title="Agent with MCP Tools", page_icon="ğŸ§ ")
else:
    # ë©”ì¸ ì•±ì€ wide ë ˆì´ì•„ì›ƒ ì‚¬ìš©
    st.set_page_config(page_title="Agent with MCP Tools", page_icon="ğŸ§ ", layout="wide")

# ë¡œê·¸ì¸ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì–´ ìˆê³  ì•„ì§ ì¸ì¦ë˜ì§€ ì•Šì€ ê²½ìš° ë¡œê·¸ì¸ í™”ë©´ í‘œì‹œ
if use_login and not st.session_state.authenticated:
    st.title("ğŸ” ë¡œê·¸ì¸")
    st.markdown("ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # ë¡œê·¸ì¸ í¼ì„ í™”ë©´ ì¤‘ì•™ì— ì¢ê²Œ ë°°ì¹˜
    with st.form("login_form"):
        username = st.text_input("ì•„ì´ë””")
        password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
        submit_button = st.form_submit_button("ë¡œê·¸ì¸")

        if submit_button:
            expected_username = os.environ.get("USER_ID")
            expected_password = os.environ.get("USER_PASSWORD")

            if username == expected_username and password == expected_password:
                st.session_state.authenticated = True
                st.success("âœ… ë¡œê·¸ì¸ ì„±ê³µ! ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
                st.rerun()
            else:
                st.error("âŒ ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # ë¡œê·¸ì¸ í™”ë©´ì—ì„œëŠ” ë©”ì¸ ì•±ì„ í‘œì‹œí•˜ì§€ ì•ŠìŒ
    st.stop()

# ì‚¬ì´ë“œë°” ìµœìƒë‹¨ì— ì €ì ì •ë³´ ì¶”ê°€ (ë‹¤ë¥¸ ì‚¬ì´ë“œë°” ìš”ì†Œë³´ë‹¤ ë¨¼ì € ë°°ì¹˜)
st.sidebar.markdown("### âœï¸ Made by [í…Œë””ë…¸íŠ¸](https://youtube.com/c/teddynote) ğŸš€")
st.sidebar.markdown(
    "### ğŸ’» [Project Page](https://github.com/teddynote-lab/langgraph-mcp-agents)"
)

st.sidebar.divider()  # êµ¬ë¶„ì„  ì¶”ê°€

# ê¸°ì¡´ í˜ì´ì§€ íƒ€ì´í‹€ ë° ì„¤ëª…
st.title("ğŸ’¬ MCP ë„êµ¬ í™œìš© ì—ì´ì „íŠ¸")
st.markdown("âœ¨ MCP ë„êµ¬ë¥¼ í™œìš©í•œ ReAct ì—ì´ì „íŠ¸ì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

SYSTEM_PROMPT = """<ROLE>
You are a smart agent with an ability to use tools. 
You will be given a question and you will use the tools to answer the question.
Pick the most relevant tool to answer the question. 
If you are failed to answer the question, try different tools to get context.
Your answer should be very polite and professional.
</ROLE>

----

<INSTRUCTIONS>
Step 1: Analyze the question
- Analyze user's question and final goal.
- If the user's question is consist of multiple sub-questions, split them into smaller sub-questions.

Step 2: Pick the most relevant tool
- Pick the most relevant tool to answer the question.
- If you are failed to answer the question, try different tools to get context.

Step 3: Answer the question
- Answer the question in the same language as the question.
- Your answer should be very polite and professional.

Step 4: Provide the source of the answer(if applicable)
- If you've used the tool, provide the source of the answer.
- Valid sources are either a website(URL) or a document(PDF, etc).

Guidelines:
- If you've used the tool, your answer should be based on the tool's output(tool's output is more important than your own knowledge).
- If you've used the tool, and the source is valid URL, provide the source(URL) of the answer.
- Skip providing the source if the source is not URL.
- Answer in the same language as the question.
- Answer should be concise and to the point.
- Avoid response your output with any other information than the answer and the source.  
</INSTRUCTIONS>

----

<OUTPUT_FORMAT>
(concise answer to the question)

**Source**(if applicable)
- (source1: valid URL)
- (source2: valid URL)
- ...
</OUTPUT_FORMAT>
"""

OUTPUT_TOKEN_INFO = {
    "claude-3-5-sonnet-latest": {"max_tokens": 8192},
    "claude-3-5-haiku-latest": {"max_tokens": 8192},
    "claude-3-7-sonnet-latest": {"max_tokens": 64000},
    "gpt-4o": {"max_tokens": 16000},
    "gpt-4o-mini": {"max_tokens": 16000},
}

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = False  # ì„¸ì…˜ ì´ˆê¸°í™” ìƒíƒœ í”Œë˜ê·¸
    st.session_state.agent = None  # ReAct ì—ì´ì „íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.history = []  # ëŒ€í™” ê¸°ë¡ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    st.session_state.mcp_client = None  # MCP í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.timeout_seconds = 120  # ì‘ë‹µ ìƒì„± ì œí•œ ì‹œê°„(ì´ˆ), ê¸°ë³¸ê°’ 120ì´ˆ
    st.session_state.selected_model = "claude-3-7-sonnet-latest"  # ê¸°ë³¸ ëª¨ë¸ ì„ íƒ
    st.session_state.recursion_limit = 100  # ì¬ê·€ í˜¸ì¶œ ì œí•œ, ê¸°ë³¸ê°’ 100

if "thread_id" not in st.session_state:
    st.session_state.thread_id = random_uuid()


# --- í•¨ìˆ˜ ì •ì˜ ë¶€ë¶„ ---


async def cleanup_mcp_client():
    """
    ê¸°ì¡´ MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤.

    ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì •ìƒì ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ í•´ì œí•©ë‹ˆë‹¤.
    """
    if "mcp_client" in st.session_state and st.session_state.mcp_client is not None:
        try:

            await st.session_state.mcp_client.__aexit__(None, None, None)
            st.session_state.mcp_client = None
        except Exception as e:
            import traceback

            # st.warning(f"MCP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # st.warning(traceback.format_exc())


def print_message():
    """
    ì±„íŒ… ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤.

    ì‚¬ìš©ìì™€ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ë©”ì‹œì§€ë¥¼ êµ¬ë¶„í•˜ì—¬ í™”ë©´ì— í‘œì‹œí•˜ê³ ,
    ë„êµ¬ í˜¸ì¶œ ì •ë³´ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ë‚´ì— í‘œì‹œí•©ë‹ˆë‹¤.
    """
    i = 0
    while i < len(st.session_state.history):
        message = st.session_state.history[i]

        if message["role"] == "user":
            st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(message["content"])
            i += 1
        elif message["role"] == "assistant":
            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ìƒì„±
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ë‚´ìš© í‘œì‹œ
                st.markdown(message["content"])

                # ë‹¤ìŒ ë©”ì‹œì§€ê°€ ë„êµ¬ í˜¸ì¶œ ì •ë³´ì¸ì§€ í™•ì¸
                if (
                    i + 1 < len(st.session_state.history)
                    and st.session_state.history[i + 1]["role"] == "assistant_tool"
                ):
                    # ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ë™ì¼í•œ ì»¨í…Œì´ë„ˆ ë‚´ì— expanderë¡œ í‘œì‹œ
                    with st.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=False):
                        st.markdown(st.session_state.history[i + 1]["content"])
                    i += 2  # ë‘ ë©”ì‹œì§€ë¥¼ í•¨ê»˜ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ 2 ì¦ê°€
                else:
                    i += 1  # ì¼ë°˜ ë©”ì‹œì§€ë§Œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ 1 ì¦ê°€
        else:
            # assistant_tool ë©”ì‹œì§€ëŠ” ìœ„ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ê±´ë„ˆëœ€
            i += 1


def get_streaming_callback(text_placeholder, tool_placeholder):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” LLMì—ì„œ ìƒì„±ë˜ëŠ” ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— í‘œì‹œí•˜ê¸° ìœ„í•œ ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    í…ìŠ¤íŠ¸ ì‘ë‹µê³¼ ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ê°ê° ë‹¤ë¥¸ ì˜ì—­ì— í‘œì‹œí•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        text_placeholder: í…ìŠ¤íŠ¸ ì‘ë‹µì„ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        tool_placeholder: ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸

    ë°˜í™˜ê°’:
        callback_func: ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¨ìˆ˜
        accumulated_text: ëˆ„ì ëœ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
        accumulated_tool: ëˆ„ì ëœ ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
    """
    accumulated_text = []
    accumulated_tool = []

    def callback_func(message: dict):
        nonlocal accumulated_text, accumulated_tool
        message_content = message.get("content", None)

        if isinstance(message_content, AIMessageChunk):
            content = message_content.content
            # ì½˜í…ì¸ ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš° (Claude ëª¨ë¸ ë“±ì—ì„œ ì£¼ë¡œ ë°œìƒ)
            if isinstance(content, list) and len(content) > 0:
                message_chunk = content[0]
                # í…ìŠ¤íŠ¸ íƒ€ì…ì¸ ê²½ìš° ì²˜ë¦¬
                if message_chunk["type"] == "text":
                    accumulated_text.append(message_chunk["text"])
                    text_placeholder.markdown("".join(accumulated_text))
                # ë„êµ¬ ì‚¬ìš© íƒ€ì…ì¸ ê²½ìš° ì²˜ë¦¬
                elif message_chunk["type"] == "tool_use":
                    if "partial_json" in message_chunk:
                        accumulated_tool.append(message_chunk["partial_json"])
                    else:
                        tool_call_chunks = message_content.tool_call_chunks
                        tool_call_chunk = tool_call_chunks[0]
                        accumulated_tool.append(
                            "\n```json\n" + str(tool_call_chunk) + "\n```\n"
                        )
                    with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                        st.markdown("".join(accumulated_tool))
            # tool_calls ì†ì„±ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (OpenAI ëª¨ë¸ ë“±ì—ì„œ ì£¼ë¡œ ë°œìƒ)
            elif (
                hasattr(message_content, "tool_calls")
                and message_content.tool_calls
                and len(message_content.tool_calls[0]["name"]) > 0
            ):
                tool_call_info = message_content.tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                    st.markdown("".join(accumulated_tool))
            # ë‹¨ìˆœ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
            elif isinstance(content, str):
                accumulated_text.append(content)
                text_placeholder.markdown("".join(accumulated_text))
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë„êµ¬ í˜¸ì¶œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            elif (
                hasattr(message_content, "invalid_tool_calls")
                and message_content.invalid_tool_calls
            ):
                tool_call_info = message_content.invalid_tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander(
                    "ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´ (ìœ íš¨í•˜ì§€ ì•ŠìŒ)", expanded=True
                ):
                    st.markdown("".join(accumulated_tool))
            # tool_call_chunks ì†ì„±ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            elif (
                hasattr(message_content, "tool_call_chunks")
                and message_content.tool_call_chunks
            ):
                tool_call_chunk = message_content.tool_call_chunks[0]
                accumulated_tool.append(
                    "\n```json\n" + str(tool_call_chunk) + "\n```\n"
                )
                with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                    st.markdown("".join(accumulated_tool))
            # additional_kwargsì— tool_callsê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (ë‹¤ì–‘í•œ ëª¨ë¸ í˜¸í™˜ì„± ì§€ì›)
            elif (
                hasattr(message_content, "additional_kwargs")
                and "tool_calls" in message_content.additional_kwargs
            ):
                tool_call_info = message_content.additional_kwargs["tool_calls"][0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                    st.markdown("".join(accumulated_tool))
        # ë„êµ¬ ë©”ì‹œì§€ì¸ ê²½ìš° ì²˜ë¦¬ (ë„êµ¬ì˜ ì‘ë‹µ)
        elif isinstance(message_content, ToolMessage):
            accumulated_tool.append(
                "\n```json\n" + str(message_content.content) + "\n```\n"
            )
            with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                st.markdown("".join(accumulated_tool))
        return None

    return callback_func, accumulated_text, accumulated_tool


async def process_query(query, text_placeholder, tool_placeholder, timeout_seconds=60):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì—ì´ì „íŠ¸ì— ì „ë‹¬í•˜ê³ , ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
    ì§€ì •ëœ ì‹œê°„ ë‚´ì— ì‘ë‹µì´ ì™„ë£Œë˜ì§€ ì•Šìœ¼ë©´ íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        query: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ í…ìŠ¤íŠ¸
        text_placeholder: í…ìŠ¤íŠ¸ ì‘ë‹µì„ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        tool_placeholder: ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        timeout_seconds: ì‘ë‹µ ìƒì„± ì œí•œ ì‹œê°„(ì´ˆ)

    ë°˜í™˜ê°’:
        response: ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ ê°ì²´
        final_text: ìµœì¢… í…ìŠ¤íŠ¸ ì‘ë‹µ
        final_tool: ìµœì¢… ë„êµ¬ í˜¸ì¶œ ì •ë³´
    """
    try:
        if st.session_state.agent:
            streaming_callback, accumulated_text_obj, accumulated_tool_obj = (
                get_streaming_callback(text_placeholder, tool_placeholder)
            )
            try:
                response = await asyncio.wait_for(
                    astream_graph(
                        st.session_state.agent,
                        {"messages": [HumanMessage(content=query)]},
                        callback=streaming_callback,
                        config=RunnableConfig(
                            recursion_limit=st.session_state.recursion_limit,
                            thread_id=st.session_state.thread_id,
                        ),
                    ),
                    timeout=timeout_seconds,
                )
            except asyncio.TimeoutError:
                error_msg = f"â±ï¸ ìš”ì²­ ì‹œê°„ì´ {timeout_seconds}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                return {"error": error_msg}, error_msg, ""

            final_text = "".join(accumulated_text_obj)
            final_tool = "".join(accumulated_tool_obj)
            return response, final_text, final_tool
        else:
            return (
                {"error": "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "",
            )
    except Exception as e:
        import traceback

        error_msg = f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        return {"error": error_msg}, error_msg, ""


async def initialize_session(mcp_config=None):
    """
    MCP ì„¸ì…˜ê³¼ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        mcp_config: MCP ë„êµ¬ ì„¤ì • ì •ë³´(JSON). Noneì¸ ê²½ìš° ê¸°ë³¸ ì„¤ì • ì‚¬ìš©

    ë°˜í™˜ê°’:
        bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
    """
    with st.spinner("ğŸ”„ MCP ì„œë²„ì— ì—°ê²° ì¤‘..."):
        # ë¨¼ì € ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì •ë¦¬
        await cleanup_mcp_client()

        if mcp_config is None:
            # config.json íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ
            mcp_config = load_config_from_json()
        client = MultiServerMCPClient(mcp_config)
        await client.__aenter__()
        tools = client.get_tools()
        st.session_state.tool_count = len(tools)
        st.session_state.mcp_client = client

        # ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ ì ì ˆí•œ ëª¨ë¸ ì´ˆê¸°í™”
        selected_model = st.session_state.selected_model

        if selected_model in [
            "claude-3-7-sonnet-latest",
            "claude-3-5-sonnet-latest",
            "claude-3-5-haiku-latest",
        ]:
            model = ChatAnthropic(
                model=selected_model,
                temperature=0.1,
                max_tokens=OUTPUT_TOKEN_INFO[selected_model]["max_tokens"],
            )
        else:  # OpenAI ëª¨ë¸ ì‚¬ìš©
            model = ChatOpenAI(
                model=selected_model,
                temperature=0.1,
                max_tokens=OUTPUT_TOKEN_INFO[selected_model]["max_tokens"],
            )
        agent = create_react_agent(
            model,
            tools,
            checkpointer=MemorySaver(),
            prompt=SYSTEM_PROMPT,
        )
        st.session_state.agent = agent
        st.session_state.session_initialized = True
        return True


# --- ì‚¬ì´ë“œë°”: ì‹œìŠ¤í…œ ì„¤ì • ì„¹ì…˜ ---
with st.sidebar:
    st.subheader("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")

    # ëª¨ë¸ ì„ íƒ ê¸°ëŠ¥
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ìƒì„±
    available_models = []

    # Anthropic API í‚¤ í™•ì¸
    has_anthropic_key = os.environ.get("ANTHROPIC_API_KEY") is not None
    if has_anthropic_key:
        available_models.extend(
            [
                "claude-3-7-sonnet-latest",
                "claude-3-5-sonnet-latest",
                "claude-3-5-haiku-latest",
            ]
        )

    # OpenAI API í‚¤ í™•ì¸
    has_openai_key = os.environ.get("OPENAI_API_KEY") is not None
    if has_openai_key:
        available_models.extend(["gpt-4o", "gpt-4o-mini"])

    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° ë©”ì‹œì§€ í‘œì‹œ
    if not available_models:
        st.warning(
            "âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— ANTHROPIC_API_KEY ë˜ëŠ” OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."
        )
        # ê¸°ë³¸ê°’ìœ¼ë¡œ Claude ëª¨ë¸ ì¶”ê°€ (í‚¤ê°€ ì—†ì–´ë„ UIë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•¨)
        available_models = ["claude-3-7-sonnet-latest"]

    # ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´
    previous_model = st.session_state.selected_model
    st.session_state.selected_model = st.selectbox(
        "ğŸ¤– ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ",
        options=available_models,
        index=(
            available_models.index(st.session_state.selected_model)
            if st.session_state.selected_model in available_models
            else 0
        ),
        help="Anthropic ëª¨ë¸ì€ ANTHROPIC_API_KEYê°€, OpenAI ëª¨ë¸ì€ OPENAI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.",
    )

    # ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œ ì„¸ì…˜ ì´ˆê¸°í™” í•„ìš” ì•Œë¦¼
    if (
        previous_model != st.session_state.selected_model
        and st.session_state.session_initialized
    ):
        st.warning(
            "âš ï¸ ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ì„¸ìš”."
        )

    # íƒ€ì„ì•„ì›ƒ ì„¤ì • ìŠ¬ë¼ì´ë” ì¶”ê°€
    st.session_state.timeout_seconds = st.slider(
        "â±ï¸ ì‘ë‹µ ìƒì„± ì œí•œ ì‹œê°„(ì´ˆ)",
        min_value=60,
        max_value=300,
        value=st.session_state.timeout_seconds,
        step=10,
        help="ì—ì´ì „íŠ¸ê°€ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ìµœëŒ€ ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ë³µì¡í•œ ì‘ì—…ì€ ë” ê¸´ ì‹œê°„ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

    st.session_state.recursion_limit = st.slider(
        "â±ï¸ ì¬ê·€ í˜¸ì¶œ ì œí•œ(íšŸìˆ˜)",
        min_value=10,
        max_value=200,
        value=st.session_state.recursion_limit,
        step=10,
        help="ì¬ê·€ í˜¸ì¶œ ì œí•œ íšŸìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ë„ˆë¬´ ë†’ì€ ê°’ì„ ì„¤ì •í•˜ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

    st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€

    # ë„êµ¬ ì„¤ì • ì„¹ì…˜ ì¶”ê°€
    st.subheader("ğŸ”§ ë„êµ¬ ì„¤ì •")

    # expander ìƒíƒœë¥¼ ì„¸ì…˜ ìƒíƒœë¡œ ê´€ë¦¬
    if "mcp_tools_expander" not in st.session_state:
        st.session_state.mcp_tools_expander = False

    # MCP ë„êµ¬ ì¶”ê°€ ì¸í„°í˜ì´ìŠ¤
    with st.expander("ğŸ§° MCP ë„êµ¬ ì¶”ê°€", expanded=st.session_state.mcp_tools_expander):
        # config.json íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œí•˜ì—¬ í‘œì‹œ
        loaded_config = load_config_from_json()
        default_config_text = json.dumps(loaded_config, indent=2, ensure_ascii=False)
        
        # pending configê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ mcp_config_text ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
        if "pending_mcp_config" not in st.session_state:
            try:
                st.session_state.pending_mcp_config = loaded_config
            except Exception as e:
                st.error(f"ì´ˆê¸° pending config ì„¤ì • ì‹¤íŒ¨: {e}")

        # ê°œë³„ ë„êµ¬ ì¶”ê°€ë¥¼ ìœ„í•œ UI
        st.subheader("ë„êµ¬ ì¶”ê°€")
        st.markdown(
            """
            [ì–´ë–»ê²Œ ì„¤ì • í•˜ë‚˜ìš”?](https://teddylee777.notion.site/MCP-1d324f35d12980c8b018e12afdf545a1?pvs=4)

            âš ï¸ **ì¤‘ìš”**: JSONì„ ë°˜ë“œì‹œ ì¤‘ê´„í˜¸(`{}`)ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤."""
        )

        # ë³´ë‹¤ ëª…í™•í•œ ì˜ˆì‹œ ì œê³µ
        example_json = {
            "github": {
                "command": "npx",
                "args": [
                    "-y",
                    "@smithery/cli@latest",
                    "run",
                    "@smithery-ai/github",
                    "--config",
                    '{"githubPersonalAccessToken":"your_token_here"}',
                ],
                "transport": "stdio",
            }
        }

        default_text = json.dumps(example_json, indent=2, ensure_ascii=False)

        new_tool_json = st.text_area(
            "ë„êµ¬ JSON",
            default_text,
            height=250,
        )

        # ì¶”ê°€í•˜ê¸° ë²„íŠ¼
        if st.button(
            "ë„êµ¬ ì¶”ê°€",
            type="primary",
            key="add_tool_button",
            use_container_width=True,
        ):
            try:
                # ì…ë ¥ê°’ ê²€ì¦
                if not new_tool_json.strip().startswith(
                    "{"
                ) or not new_tool_json.strip().endswith("}"):
                    st.error("JSONì€ ì¤‘ê´„í˜¸({})ë¡œ ì‹œì‘í•˜ê³  ëë‚˜ì•¼ í•©ë‹ˆë‹¤.")
                    st.markdown('ì˜¬ë°”ë¥¸ í˜•ì‹: `{ "ë„êµ¬ì´ë¦„": { ... } }`')
                else:
                    # JSON íŒŒì‹±
                    parsed_tool = json.loads(new_tool_json)

                    # mcpServers í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³  ì²˜ë¦¬
                    if "mcpServers" in parsed_tool:
                        # mcpServers ì•ˆì˜ ë‚´ìš©ì„ ìµœìƒìœ„ë¡œ ì´ë™
                        parsed_tool = parsed_tool["mcpServers"]
                        st.info(
                            "'mcpServers' í˜•ì‹ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
                        )

                    # ì…ë ¥ëœ ë„êµ¬ ìˆ˜ í™•ì¸
                    if len(parsed_tool) == 0:
                        st.error("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ë„êµ¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    else:
                        # ëª¨ë“  ë„êµ¬ì— ëŒ€í•´ ì²˜ë¦¬
                        success_tools = []
                        for tool_name, tool_config in parsed_tool.items():
                            # URL í•„ë“œ í™•ì¸ ë° transport ì„¤ì •
                            if "url" in tool_config:
                                # URLì´ ìˆëŠ” ê²½ìš° transportë¥¼ "sse"ë¡œ ì„¤ì •
                                tool_config["transport"] = "sse"
                                st.info(
                                    f"'{tool_name}' ë„êµ¬ì— URLì´ ê°ì§€ë˜ì–´ transportë¥¼ 'sse'ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤."
                                )
                            elif "transport" not in tool_config:
                                # URLì´ ì—†ê³  transportë„ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ "stdio" ì„¤ì •
                                tool_config["transport"] = "stdio"

                            # í•„ìˆ˜ í•„ë“œ í™•ì¸
                            if (
                                "command" not in tool_config
                                and "url" not in tool_config
                            ):
                                st.error(
                                    f"'{tool_name}' ë„êµ¬ ì„¤ì •ì—ëŠ” 'command' ë˜ëŠ” 'url' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
                                )
                            elif "command" in tool_config and "args" not in tool_config:
                                st.error(
                                    f"'{tool_name}' ë„êµ¬ ì„¤ì •ì—ëŠ” 'args' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
                                )
                            elif "command" in tool_config and not isinstance(
                                tool_config["args"], list
                            ):
                                st.error(
                                    f"'{tool_name}' ë„êµ¬ì˜ 'args' í•„ë“œëŠ” ë°˜ë“œì‹œ ë°°ì—´([]) í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                                )
                            else:
                                # pending_mcp_configì— ë„êµ¬ ì¶”ê°€
                                st.session_state.pending_mcp_config[tool_name] = (
                                    tool_config
                                )
                                success_tools.append(tool_name)

                        # ì„±ê³µ ë©”ì‹œì§€
                        if success_tools:
                            if len(success_tools) == 1:
                                st.success(
                                    f"{success_tools[0]} ë„êµ¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                                )
                            else:
                                tool_names = ", ".join(success_tools)
                                st.success(
                                    f"ì´ {len(success_tools)}ê°œ ë„êµ¬({tool_names})ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                                )
                            # ì¶”ê°€ë˜ë©´ expanderë¥¼ ì ‘ì–´ì¤Œ
                            st.session_state.mcp_tools_expander = False
                            st.rerun()
            except json.JSONDecodeError as e:
                st.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
                st.markdown(
                    f"""
                **ìˆ˜ì • ë°©ë²•**:
                1. JSON í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
                2. ëª¨ë“  í‚¤ëŠ” í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
                3. ë¬¸ìì—´ ê°’ë„ í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
                4. ë¬¸ìì—´ ë‚´ì—ì„œ í°ë”°ì˜´í‘œë¥¼ ì‚¬ìš©í•  ê²½ìš° ì´ìŠ¤ì¼€ì´í”„(\\")í•´ì•¼ í•©ë‹ˆë‹¤.
                """
                )
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ë“±ë¡ëœ ë„êµ¬ ëª©ë¡ í‘œì‹œ ë° ì‚­ì œ ë²„íŠ¼ ì¶”ê°€
    with st.expander("ğŸ“‹ ë“±ë¡ëœ ë„êµ¬ ëª©ë¡", expanded=True):
        try:
            pending_config = st.session_state.pending_mcp_config
        except Exception as e:
            st.error("ìœ íš¨í•œ MCP ë„êµ¬ ì„¤ì •ì´ ì•„ë‹™ë‹ˆë‹¤.")
        else:
            # pending configì˜ í‚¤(ë„êµ¬ ì´ë¦„) ëª©ë¡ì„ ìˆœíšŒí•˜ë©° í‘œì‹œ
            for tool_name in list(pending_config.keys()):
                col1, col2 = st.columns([8, 2])
                col1.markdown(f"- **{tool_name}**")
                if col2.button("ì‚­ì œ", key=f"delete_{tool_name}"):
                    # pending configì—ì„œ í•´ë‹¹ ë„êµ¬ ì‚­ì œ (ì¦‰ì‹œ ì ìš©ë˜ì§€ëŠ” ì•ŠìŒ)
                    del st.session_state.pending_mcp_config[tool_name]
                    st.success(
                        f"{tool_name} ë„êµ¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                    )

    st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€

# --- ì‚¬ì´ë“œë°”: ì‹œìŠ¤í…œ ì •ë³´ ë° ì‘ì—… ë²„íŠ¼ ì„¹ì…˜ ---
with st.sidebar:
    st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
    st.write(f"ğŸ› ï¸ MCP ë„êµ¬ ìˆ˜: {st.session_state.get('tool_count', 'ì´ˆê¸°í™” ì¤‘...')}")
    selected_model_name = st.session_state.selected_model
    st.write(f"ğŸ§  í˜„ì¬ ëª¨ë¸: {selected_model_name}")

    # ì„¤ì • ì ìš©í•˜ê¸° ë²„íŠ¼ì„ ì—¬ê¸°ë¡œ ì´ë™
    if st.button(
        "ì„¤ì • ì ìš©í•˜ê¸°",
        key="apply_button",
        type="primary",
        use_container_width=True,
    ):
        # ì ìš© ì¤‘ ë©”ì‹œì§€ í‘œì‹œ
        apply_status = st.empty()
        with apply_status.container():
            st.warning("ğŸ”„ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            progress_bar = st.progress(0)

            # ì„¤ì • ì €ì¥
            st.session_state.mcp_config_text = json.dumps(
                st.session_state.pending_mcp_config, indent=2, ensure_ascii=False
            )

            # config.json íŒŒì¼ì— ì„¤ì • ì €ì¥
            save_result = save_config_to_json(st.session_state.pending_mcp_config)
            if not save_result:
                st.error("âŒ ì„¤ì • íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            progress_bar.progress(15)

            # ì„¸ì…˜ ì´ˆê¸°í™” ì¤€ë¹„
            st.session_state.session_initialized = False
            st.session_state.agent = None

            # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
            progress_bar.progress(30)

            # ì´ˆê¸°í™” ì‹¤í–‰
            success = st.session_state.event_loop.run_until_complete(
                initialize_session(st.session_state.pending_mcp_config)
            )

            # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
            progress_bar.progress(100)

            if success:
                st.success("âœ… ìƒˆë¡œìš´ ì„¤ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                # ë„êµ¬ ì¶”ê°€ expander ì ‘ê¸°
                if "mcp_tools_expander" in st.session_state:
                    st.session_state.mcp_tools_expander = False
            else:
                st.error("âŒ ì„¤ì • ì ìš©ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

    st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€

    # ì‘ì—… ë²„íŠ¼ ì„¹ì…˜
    st.subheader("ğŸ”„ ì‘ì—…")

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True, type="primary"):
        # thread_id ì´ˆê¸°í™”
        st.session_state.thread_id = random_uuid()

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        st.session_state.history = []

        # ì•Œë¦¼ ë©”ì‹œì§€
        st.success("âœ… ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

    # ë¡œê·¸ì¸ ê¸°ëŠ¥ì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼ í‘œì‹œ
    if use_login and st.session_state.authenticated:
        st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True, type="secondary"):
            st.session_state.authenticated = False
            st.success("âœ… ë¡œê·¸ì•„ì›ƒ ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()

# --- ê¸°ë³¸ ì„¸ì…˜ ì´ˆê¸°í™” (ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°) ---
if not st.session_state.session_initialized:
    st.info(
        "MCP ì„œë²„ì™€ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”."
    )


# --- ëŒ€í™” ê¸°ë¡ ì¶œë ¥ ---
print_message()

# --- ì‚¬ìš©ì ì…ë ¥ ë° ì²˜ë¦¬ ---
user_query = st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
if user_query:
    if st.session_state.session_initialized:
        st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(user_query)
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            tool_placeholder = st.empty()
            text_placeholder = st.empty()
            resp, final_text, final_tool = (
                st.session_state.event_loop.run_until_complete(
                    process_query(
                        user_query,
                        text_placeholder,
                        tool_placeholder,
                        st.session_state.timeout_seconds,
                    )
                )
            )
        if "error" in resp:
            st.error(resp["error"])
        else:
            st.session_state.history.append({"role": "user", "content": user_query})
            st.session_state.history.append(
                {"role": "assistant", "content": final_text}
            )
            if final_tool.strip():
                st.session_state.history.append(
                    {"role": "assistant_tool", "content": final_tool}
                )
            st.rerun()
    else:
        st.warning(
            "âš ï¸ MCP ì„œë²„ì™€ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”."
        )
