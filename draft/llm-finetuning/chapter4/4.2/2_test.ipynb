{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b06f1e7-2e8d-498b-b148-3f30ba4736c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# 저장된 train 데이터를 불러옵니다.\n",
    "dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476fad0f-cf4a-4db6-956a-821cec5752d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trl\n",
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "from peft import LoraConfig, PeftConfig, AutoPeftModelForCausalLM\n",
    "\n",
    "import wandb\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          pipeline)\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b589a6d-061e-47df-89c7-f6213f20f471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3431a7ff2a6048248ddae68fe4c3c21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "# 학습한 모델을 경로를 지정합니다.\n",
    "peft_model_id = \"./code-llama3-8B-text-to-sql\"\n",
    "\n",
    "# PEFT 어댑터를 통해 사전 학습된 모델을 로드합니다.\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  peft_model_id,\n",
    "  device_map=\"auto\",\n",
    "  torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 토크나이저 로드합니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
    "tokenizer.padding_side = 'right'  \n",
    "\n",
    "# 생성을 조금 더 효율적으로 하기 위해 파이프라인을 불러옵니다.\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc741bc-cae1-4a65-939b-b18b7070a113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Task: 지난 학기 STATS 520의 GSI는 누구였나요?\n",
      "SQL table: CREATE TABLE jobs (\n",
      "    job_id int,\n",
      "    job_title varchar,\n",
      "    description varchar,\n",
      "    requirement varchar,\n",
      "    city varchar,\n",
      "    state varchar,\n",
      "    country varchar,\n",
      "    zip int\n",
      ")\n",
      "\n",
      "CREATE TABLE ta (\n",
      "    campus_job_id int,\n",
      "    student_id int,\n",
      "    location varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE program_requirement (\n",
      "    program_id int,\n",
      "    category varchar,\n",
      "    min_credit int,\n",
      "    additional_req varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE program_course (\n",
      "    program_id int,\n",
      "    course_id int,\n",
      "    workload int,\n",
      "    category varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE requirement (\n",
      "    requirement_id int,\n",
      "    requirement varchar,\n",
      "    college varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE gsi (\n",
      "    course_offering_id int,\n",
      "    student_id int\n",
      ")\n",
      "\n",
      "CREATE TABLE course (\n",
      "    course_id int,\n",
      "    name varchar,\n",
      "    department varchar,\n",
      "    number varchar,\n",
      "    credits varchar,\n",
      "    advisory_requirement varchar,\n",
      "    enforced_requirement varchar,\n",
      "    description varchar,\n",
      "    num_semesters int,\n",
      "    num_enrolled int,\n",
      "    has_discussion varchar,\n",
      "    has_lab varchar,\n",
      "    has_projects varchar,\n",
      "    has_exams varchar,\n",
      "    num_reviews int,\n",
      "    clarity_score int,\n",
      "    easiness_score int,\n",
      "    helpfulness_score int\n",
      ")\n",
      "\n",
      "CREATE TABLE semester (\n",
      "    semester_id int,\n",
      "    semester varchar,\n",
      "    year int\n",
      ")\n",
      "\n",
      "CREATE TABLE offering_instructor (\n",
      "    offering_instructor_id int,\n",
      "    offering_id int,\n",
      "    instructor_id int\n",
      ")\n",
      "\n",
      "CREATE TABLE program (\n",
      "    program_id int,\n",
      "    name varchar,\n",
      "    college varchar,\n",
      "    introduction varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE student_record (\n",
      "    student_id int,\n",
      "    course_id int,\n",
      "    semester int,\n",
      "    grade varchar,\n",
      "    how varchar,\n",
      "    transfer_source varchar,\n",
      "    earn_credit varchar,\n",
      "    repeat_term varchar,\n",
      "    test_id varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE course_prerequisite (\n",
      "    pre_course_id int,\n",
      "    course_id int\n",
      ")\n",
      "\n",
      "CREATE TABLE course_offering (\n",
      "    offering_id int,\n",
      "    course_id int,\n",
      "    semester int,\n",
      "    section_number int,\n",
      "    start_time time,\n",
      "    end_time time,\n",
      "    monday varchar,\n",
      "    tuesday varchar,\n",
      "    wednesday varchar,\n",
      "    thursday varchar,\n",
      "    friday varchar,\n",
      "    saturday varchar,\n",
      "    sunday varchar,\n",
      "    has_final_project varchar,\n",
      "    has_final_exam varchar,\n",
      "    textbook varchar,\n",
      "    class_address varchar,\n",
      "    allow_audit varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE instructor (\n",
      "    instructor_id int,\n",
      "    name varchar,\n",
      "    uniqname varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE area (\n",
      "    course_id int,\n",
      "    area varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE comment_instructor (\n",
      "    instructor_id int,\n",
      "    student_id int,\n",
      "    score int,\n",
      "    comment_text varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE student (\n",
      "    student_id int,\n",
      "    lastname varchar,\n",
      "    firstname varchar,\n",
      "    program_id int,\n",
      "    declare_major varchar,\n",
      "    total_credit int,\n",
      "    total_gpa float,\n",
      "    entered_as varchar,\n",
      "    admit_term int,\n",
      "    predicted_graduation_semester int,\n",
      "    degree varchar,\n",
      "    minor varchar,\n",
      "    internship varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE course_tags_count (\n",
      "    course_id int,\n",
      "    clear_grading int,\n",
      "    pop_quiz int,\n",
      "    group_projects int,\n",
      "    inspirational int,\n",
      "    long_lectures int,\n",
      "    extra_credit int,\n",
      "    few_tests int,\n",
      "    good_feedback int,\n",
      "    tough_tests int,\n",
      "    heavy_papers int,\n",
      "    cares_for_students int,\n",
      "    heavy_assignments int,\n",
      "    respected int,\n",
      "    participation int,\n",
      "    heavy_reading int,\n",
      "    tough_grader int,\n",
      "    hilarious int,\n",
      "    would_take_again int,\n",
      "    good_lecture int,\n",
      "    no_skip int\n",
      ")\n",
      "SQL query: \n",
      "Original Answer:\n",
      "SELECT DISTINCT student.firstname, student.lastname FROM course INNER JOIN course_offering ON course.course_id = course_offering.course_id INNER JOIN gsi ON gsi.course_offering_id = course_offering.offering_id INNER JOIN student ON student.student_id = gsi.student_id INNER JOIN semester ON semester.semester_id = course_offering.semester WHERE course.department = 'STATS' AND course.number = 520 AND semester.semester = 'FA' AND semester.year = 2015\n",
      "Generated Answer:\n",
      "SELECT DISTINCT student.firstname, student.lastname FROM student INNER JOIN student_record ON student.student_id = student_record.student_id INNER JOIN course ON course.course_id = student_record.course_id WHERE course.department = 'STATS' AND course.number = 520 AND student_record.semester = (SELECT MAX(SEMESTERalias0.semester_id) FROM semester AS SEMESTERalias0 INNER JOIN course_offering AS COURSE_OFFERINGalias1 ON SEMESTERalias0.semester_id = COURSE_OFFERINGalias1.semester INNER JOIN course AS COURSEalias1 ON COURSEalias1.course_id = COURSE_OFFERINGalias1.course_id WHERE COURSEalias1.department = 'STATS' AND COURSEalias1.number = 520 AND SEMESTERalias0.year < 2016)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 테스트 데이터를 불러옵니다.\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")\n",
    "rand_idx = randint(0, len(eval_dataset))\n",
    "\n",
    "# 샘플 데이터 설정합니다.\n",
    "prompt = pipe.tokenizer.apply_chat_template(eval_dataset[rand_idx][\"messages\"][:2], tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=False, temperature=0.1, top_k=50, top_p=0.1, eos_token_id=pipe.tokenizer.eos_token_id, pad_token_id=pipe.tokenizer.pad_token_id)\n",
    "\n",
    "print(f\"Query:\\n{eval_dataset[rand_idx]['messages'][1]['content']}\")\n",
    "print(f\"Original Answer:\\n{eval_dataset[rand_idx]['messages'][2]['content']}\".replace(\"<|im_end|>\", \"\"))\n",
    "print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n",
    "eval_dataset[rand_idx]['messages'][2]['content'].replace(\"<|im_end|>\", \"\") == outputs[0]['generated_text'][len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b083ba-143a-4f2d-966a-87d165709117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1f68e781e340059adec03ffc1ba38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "def evaluate(sample):\n",
    "    prompt = pipe.tokenizer.apply_chat_template(sample[\"messages\"][:2], tokenize=False, add_generation_prompt=True)\n",
    "    outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95, eos_token_id=pipe.tokenizer.eos_token_id, pad_token_id=pipe.tokenizer.pad_token_id)\n",
    "    predicted_answer = outputs[0]['generated_text'][len(prompt):].strip()\n",
    "    return (sample[\"messages\"][1][\"content\"], predicted_answer, sample[\"messages\"][2][\"content\"])\n",
    "\n",
    "success_rate = []\n",
    "for i in tqdm(range(8740, len(eval_dataset))):\n",
    "    success_rate.append(evaluate(eval_dataset[i]))\n",
    "\n",
    "with open(\"./success_rate3.txt\", \"w\") as f:\n",
    "    for s in success_rate:\n",
    "        f.write(str(s) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd942e6-8c89-4dcf-a99d-569b18fea4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
