{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47e94eb",
   "metadata": {},
   "source": [
    "# GPT4All\n",
    "\n",
    "![](./images/gpt4all.png)\n",
    "\n",
    "[GitHub:nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all) 은 코드, 채팅 형식의 대화를 포함한 방대한 양의 데이터로 학습된 오픈 소스 챗봇 생태계입니다.\n",
    "\n",
    "이 예제에서는 LangChain을 사용하여 `GPT4All` 모델과 상호 작용하는 방법에 대해 설명합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2927024",
   "metadata": {},
   "source": [
    "## 설치방법\n",
    "\n",
    "1. 먼저, 공식 홈페이지에 접속하여 설치파일을 다운로드 받아 설치합니다\n",
    "2. [공식 홈페이지](https://gpt4all.io/index.html) 바로가기\n",
    "3. 파이썬 패키지를 설치합니다.\n",
    "4. [pip 를 활용한 설치 방법](https://github.com/nomic-ai/gpt4all/blob/main/gpt4all-bindings/python/README.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efa7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU gpt4all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff73a4",
   "metadata": {},
   "source": [
    "## 모델 다운로드\n",
    "\n",
    "![](./images/gpt4all_models.png)\n",
    "\n",
    "[gpt4all 페이지](https://gpt4all.io/index.html)에는 `Model Explorer` 섹션이 있습니다.\n",
    "(더 많은 정보를 원하시면 https://github.com/nomic-ai/gpt4all 을 방문하세요.)\n",
    "\n",
    "1. [공식 홈페이지](https://gpt4all.io/index.html) 에서 다운로드 가능한 모델을 다운로드 받습니다. 본인의 PC 사양에서 구동가능한 모델을 선택하는 것이 좋습니다.\n",
    "2. 본 튜토리얼에서는 `EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf`(10.69GB) 모델을 다운로드 받아 진행하겠습니다.\n",
    "3. 다운로드 받은 모델은 `models` 폴더 생성 후 해당 폴더에 다운로드 받습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80118f",
   "metadata": {},
   "source": [
    "- `local_path` 변수에 로컬 파일 경로(`\"./models/EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf\"`)를 할당합니다.\n",
    "- 이 경로는 사용자가 원하는 로컬 파일 경로로 대체할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"./models/EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf\"  # 원하는 로컬 파일 경로로 대체하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3d3f5",
   "metadata": {},
   "source": [
    "## 모델 정보 설정\n",
    "\n",
    "로컬에서 실행하려면 호환되는 ggml 형식의 모델을 다운로드하세요.\n",
    "\n",
    "- 관심 있는 모델을 선택하세요.\n",
    "- UI를 사용하여 다운로드하고 `.bin` 파일을 `local_path`(아래 참고)로 이동시키세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc95d0c2",
   "metadata": {},
   "source": [
    "### GPT4ALL 모델 활용\n",
    "\n",
    "`GPT4All`은 GPT-3와 유사한 대규모 언어 모델로, 다양한 자연어 처리 작업에 활용될 수 있습니다.\n",
    "\n",
    "이 모듈을 사용하면 GPT4All 모델을 간편하게 로드하고 추론에 활용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"<s>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>\n",
    "<s>Human: {question}</s>\n",
    "<s>Assistant:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# GPT4All 언어 모델 초기화\n",
    "# model는 GPT4All 모델 파일의 경로를 지정\n",
    "llm = GPT4All(\n",
    "    model=local_path,\n",
    "    backend=\"gpu\",  # GPU 설정\n",
    "    streaming=True,  # 스트리밍 설정\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],  # 콜백 설정\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 질의 실행\n",
    "response = chain.invoke({\"question\": \"대한민국의 수도는 어디인가요?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
