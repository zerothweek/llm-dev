{"cells":[{"cell_type":"markdown","metadata":{},"source":["# OpenAI 외 도구 호출 에이전트(Tool Calling Agent)\n","\n","OpenAI 외에도 `Anthropic`, `Google Gemini`, `Together.ai`, `Ollama`, `Mistral`과 같은 더 광범위한 공급자 구현을 지원합니다.\n","\n","이번 챕터에서는 다양한 LLM 을 사용하여 도구 호출 에이전트를 생성하고 실행하는 방법을 살펴보겠습니다.\n","\n","**참고 링크**\n","\n","- [LangChain 공식 도큐먼트](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# API 키를 환경변수로 관리하기 위한 설정 파일\n","from dotenv import load_dotenv\n","\n","# API 키 정보 로드\n","load_dotenv()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# LangSmith 추적을 설정합니다. https://smith.langchain.com\n","# !pip install -qU langchain-teddynote\n","from langchain_teddynote import logging\n","\n","# 프로젝트 이름을 입력합니다.\n","logging.langsmith(\"CH15-Agents\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.tools import tool\n","from typing import List, Dict\n","from langchain_teddynote.tools import GoogleNews\n","\n","\n","# 도구 정의\n","@tool\n","def search_news(query: str) -> List[Dict[str, str]]:\n","    \"\"\"Search Google News by input keyword\"\"\"\n","    news_tool = GoogleNews()\n","    return news_tool.search_by_keyword(query, k=5)\n","\n","\n","print(f\"도구 이름: {search_news.name}\")\n","print(f\"도구 설명: {search_news.description}\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# tools 정의\n","tools = [search_news]"]},{"cell_type":"markdown","metadata":{},"source":["## Agent 용 프롬프트 생성\n","\n","- `chat_history` : 이전 대화 내용을 저장하는 변수 (멀티턴을 지원하지 않는다면, 생략 가능합니다.)\n","- `agent_scratchpad` : 에이전트가 임시로 저장하는 변수\n","- `input` : 사용자의 입력"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain.agents import create_tool_calling_agent\n","\n","# 프롬프트 생성\n","# 프롬프트는 에이전트에게 모델이 수행할 작업을 설명하는 텍스트를 제공합니다. (도구의 이름과 역할을 입력)\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant. \"\n","            \"Make sure to use the `search_news` tool for searching keyword related news.\",\n","        ),\n","        (\"placeholder\", \"{chat_history}\"),\n","        (\"human\", \"{input}\"),\n","        (\"placeholder\", \"{agent_scratchpad}\"),\n","    ]\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Tool Calling 을 지원하는 다양한 LLM 목록\n","\n","실습 진행을 위해서는 아래 내용을 설정해야 합니다.\n","\n","**Anthropic**\n","\n","- [Anthropic API 키 발급 관련](https://console.anthropic.com/settings/keys)\n","- `.env` 파일 내 `ANTHROPIC_API_KEY` 에 발급받은 키를 설정하세요\n","\n","**Gemini**\n","\n","- [Gemini API 키 발급 관련](https://aistudio.google.com/app/apikey?hl=ko)\n","- `.env` 파일 내 `GOOGLE_API_KEY` 에 발급받은 키를 설정하세요\n","\n","**Together AI**\n","\n","- [Together AI API 키 발급 관련](https://api.together.ai/)\n","- `.env` 파일 내 `TOGETHER_API_KEY` 에 발급받은 키를 설정하세요\n","\n","**Ollama**\n","\n","- [Ollama Tool Calling 지원 모델 리스트](https://ollama.com/search?c=tools)\n","- [이번 실습에 사용할 llama3.1 모델](https://ollama.com/library/llama3.1)\n","- 터미널 창에 `ollama pull llama3.1` 명령어를 입력하여 모델을 다운로드 받습니다.\n","- 이전에 Ollama 를 사용하지 않았다면, [Ollama](https://wikidocs.net/233805) 를 참고해 주세요."]},{"cell_type":"markdown","metadata":{},"source":["langchain-ollama 설치를 한 뒤 진행해 주세요."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# !pip install -qU langchain-ollama==0.1.3"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from langchain_anthropic import ChatAnthropic\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain_openai import ChatOpenAI\n","from langchain_ollama import ChatOllama\n","import os\n","\n","# GPT-4o-mini\n","gpt = ChatOpenAI(model=\"gpt-4o-mini\")\n","\n","# Claude-3-5-sonnet\n","claude = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)\n","\n","# Gemini-1.5-pro-latest\n","gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n","\n","# Llama-3.1-70B-Instruct-Turbo\n","llama = ChatOpenAI(\n","    base_url=\"https://api.together.xyz/v1\",\n","    api_key=os.environ[\"TOGETHER_API_KEY\"],\n","    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",")\n","\n","# Llama-3.1\n","ollama = ChatOllama(model=\"llama3.1\", temperature=0)\n","\n","# Qwen2.5 7B (한글 성능 괜찮은 편)\n","qwen = ChatOllama(\n","    model=\"qwen2.5:latest\",\n",")"]},{"cell_type":"markdown","metadata":{},"source":["LLM 기반으로 Agent 를 생성합니다."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from langchain.agents import create_tool_calling_agent\n","\n","# Agent 생성\n","gpt_agent = create_tool_calling_agent(gpt, tools, prompt)\n","claude_agent = create_tool_calling_agent(claude, tools, prompt)\n","gemini_agent = create_tool_calling_agent(gemini, tools, prompt)\n","llama_agent = create_tool_calling_agent(llama, tools, prompt)\n","ollama_agent = create_tool_calling_agent(ollama, tools, prompt)\n","qwen_agent = create_tool_calling_agent(qwen, tools, prompt)"]},{"cell_type":"markdown","metadata":{},"source":["## AgentExecutor 생성 후 실행 및 결과 확인\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.agents import AgentExecutor\n","\n","# gpt_agent 실행\n","agent_executor = AgentExecutor(\n","    agent=gpt_agent,\n","    tools=tools,\n","    verbose=True,\n","    handle_parsing_errors=True,\n",")\n","\n","result = agent_executor.invoke({\"input\": \"AI 투자와 관련된 뉴스를 검색해 주세요.\"})\n","\n","print(\"Agent 실행 결과:\")\n","print(result[\"output\"])"]},{"cell_type":"markdown","metadata":{},"source":["다양한 llm을 사용하여 에이전트를 실행합니다.\n","\n","다음은 입력받은 llm을 사용하여 Agent 를 생성하고 실행하여 결과를 출력하는 함수입니다."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def execute_agent(llm, tools, input_text, label):\n","    agent = create_tool_calling_agent(llm, tools, prompt)\n","    executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n","    result = executor.invoke({\"input\": input_text})\n","    print(f\"[{label}] 결과입니다.\")\n","    if isinstance(result[\"output\"], list) and len(result[\"output\"]) > 0:\n","        for item in result[\"output\"]:\n","            if \"text\" in item:\n","                print(item[\"text\"])\n","    elif isinstance(result[\"output\"], str):\n","        print(result[\"output\"])\n","    else:\n","        print(result[\"output\"])"]},{"cell_type":"markdown","metadata":{},"source":["각 llm 별로 에이전트를 생성하고 실행하여 결과를 출력합니다."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["query = (\n","    \"AI 투자와 관련된 뉴스를 검색하고, 결과를 Instagram 게시글 형식으로 작성해 주세요.\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# gpt\n","execute_agent(gpt, tools, query, \"gpt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# claude\n","execute_agent(claude, tools, query, \"claude\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# gemini\n","execute_agent(gemini, tools, query, \"gemini\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# llama3.1 70B (Together.ai)\n","execute_agent(\n","    llama,\n","    tools,\n","    \"Search AI related news and write it in Instagram post format\",\n","    \"llama3.1 70B\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# llama3.1 8B (ollama)\n","execute_agent(ollama, tools, query, \"llama3.1(Ollama)\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# qwen2.5 7B (ollama)\n","query = \"AI 투자와 관련된 뉴스를 검색하고, 결과를 Instagram 게시글 형식으로 작성해 주세요. 한글로 답변하세요!\"\n","\n","execute_agent(qwen, tools, query, \"qwen2.5(Ollama)\")"]}],"metadata":{"kernelspec":{"display_name":"langchain-kr-lwwSZlnu-py3.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}
